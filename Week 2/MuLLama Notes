MuLLama Model: Designed to understand music and answer music-related questions.
- Generates captions for music files using audio representations.
- Outperforms state-of-the-art (SOTA) models in both music question answering and captioning.
- Generated by adapting existing music captioning datasets like MusicCaps and MagnaTagATune to create open-ended music question-answer pairs.
- Utilizes the MPT model to generate question-answer pairs based on music captions or tags.
- The MERT model is employed to extract music features from raw audio.
